Building DAG of jobs...
Provided cores: 2
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	num_reads
	1

rule num_reads:
    input: /hpc/hub_oudenaarden/aalemany/emma-adi/mouse/SvdB11d2-MitoTrackerThird-Satellites-Adult.sam.gz
    output: /hpc/hub_oudenaarden/edann/hexamers/rnaseq/mouse/test_snakemake/SvdB11d2-MitoTrackerThird-Satellites-Adult.numReads.txt
    jobid: 0
    wildcards: dir=/hpc/hub_oudenaarden/edann/hexamers/rnaseq/mouse/test_snakemake, sample=SvdB11d2-MitoTrackerThird-Satellites-Adult

Error in rule num_reads:
    jobid: 0
    output: /hpc/hub_oudenaarden/edann/hexamers/rnaseq/mouse/test_snakemake/SvdB11d2-MitoTrackerThird-Satellites-Adult.numReads.txt

RuleException:
WorkflowError in line 50 of /hpc/hub_oudenaarden/edann/bin/coverage_bias/Snakefile:
URLError: <urlopen error [Errno 2] No such file or directory: '/hpc/hub_oudenaarden/edann/bin/coverage_bias/numReadsPerCell.py -o /hpc/hub_oudenaarden/edann/hexamers/rnaseq/mouse/test_snakemake /hpc/hub_oudenaarden/aalemany/emma-adi/mouse/SvdB11d2-MitoTrackerThird-Satellites-Adult.sam.gz'>
  File "/hpc/hub_oudenaarden/edann/bin/coverage_bias/Snakefile", line 50, in __rule_num_reads
  File "/hpc/local/CentOS7/common/lang/python/3.6.1/lib/python3.6/concurrent/futures/thread.py", line 55, in run
Will exit after finishing currently running jobs.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2018-02-26T094910.923286.snakemake.log
